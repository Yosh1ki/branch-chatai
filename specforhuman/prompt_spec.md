---
# プロンプト仕様書（Branch: MVP版）

本ドキュメントでは、Branch プロダクトにおける LLM プロンプトの仕様（テンプレート構造と設計意図）を定義します。
---

## 🧠 1. システムプロンプト共通仕様

Branch では、どのモデルを使用しても以下のような基本構造を持つプロンプトを採用します。

```
[SYSTEM]
あなたは論理的で丁寧に回答するアシスタントです。
ユーザーの会話履歴と要望に基づいて、適切な回答をしてください。
必要に応じて、丁寧に補足情報や例示も行ってください。
会話分岐（ブランチ）がある場合、その文脈も踏まえてください。
```

---

## 🗂️ 2. プロンプト構造

プロンプトは以下の 3 要素を組み合わせて構築します：

| セクション   | 内容説明                                          |
| ------------ | ------------------------------------------------- |
| システム     | 上記のルールベース（アシスタントの振る舞い規定）  |
| コンテキスト | 会話履歴（親チェーン履歴 + 要約）                 |
| ユーザー     | 現在のユーザー入力（メッセージ内容）              |

---

## 🪜 3. コンテキストルール（ブランチ込み）

### 3.1 階層ルール

-   **現在のブランチから親チェーンをルートまで遡る**
-   共通履歴（分岐点より前）は必ず含める
-   兄弟ブランチの履歴は含めない

### 3.2 メッセージ最大数

-   1 ブランチの履歴は **直近 40 件** を上限とする
-   40 件を超える分は要約 JSON に置換する

### 3.3 要約スキーマ

-   summary / key_facts / user_goal / action_items / sentiment / entities / last_updated / turn_count

---

## 🧩 4. 使用モデルごとのテンプレート調整

| モデル名                 | プロンプト調整ポイント                   |
| ------------------------ | ---------------------------------------- |
| gpt-5.2-chat-latest / gpt-5.2 | シンプルな指示＋文脈のみで十分        |
| claude-sonnet-4-5        | 文学的表現を避け、論理的に答える旨を追加 |
| gemini-3-pro-preview     | アシスタントの指示再確認を明記           |

---

## 📦 5. 最終プロンプト例

```
[SYSTEM]
あなたは論理的で丁寧に回答するアシスタントです。
常に、ユーザーのコンテキストを踏まえて、ブランチの経緯を考慮してください。

[CONTEXT]
- 会話開始: {"content": "LEDディスプレイの仕組みを教えて"}
- ブランチ1: {"content": "それはエネルギー効率的ですか？"}
- 直近の会話: {"content": "その場合の寿命はどのくらいですか？"}
- 要約: {"summary": "..."}

[USER]
LEDの寿命を延ばす具体的な方法は何ですか？
```

---

## 📜 6. 開発上の備考

-   LangChain の `ChatPromptTemplate` を使って構築することを想定
-   コンテキスト（履歴）生成は LangGraph 側のステート管理に委ねる
-   要約は固定の要約モデル（`gpt-4o-mini`）で生成する

---

以上。
