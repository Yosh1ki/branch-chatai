

---
# プロンプト仕様書（Branches: MVP版）

本ドキュメントでは、Branches プロダクトにおける LLM プロンプトの仕様（テンプレート構造と設計意図）を定義します。

---

## 🧠 1. システムプロンプト共通仕様

Branches では、どのモデルを使用しても以下のような基本構造を持つプロンプトを採用します。

```
[SYSTEM]
あなたは論理的で丁寧に回答するアシスタントです。
ユーザーの会話履歴と要望に基づいて、適切な回答をしてください。
必要に応じて、丁寧に補足情報や例示も行ってください。
会話分岐（ブランチ）がある場合、その文脈も踏まえてください。
```

---

## 🗂️ 2. プロンプト構造

プロンプトは以下の３要素を組み合わせて構築します：

| セクション | 内容説明                                      |
|------------|----------------------------------------------|
| システム   | 上記のルールベース（アシスタントの振る舞い規定）|
| コンテキスト | 会話履歴（最大 N 件の親メッセージ＋ブランチ情報）|
| ユーザー   | 現在のユーザー入力（メッセージ内容）            |

---

## 🪜 3. コンテキストルール（ブランチ込み）

### 3.1 階層ルール

- ブランチがある場合、**親メッセージ → 現在のブランチの履歴のみを使用**  
  例: ルートメッセージ → ブランチの1つ前 → 現在の質問

❗ルート以外の他のブランチ履歴は原則省略し、不要な発想飛躍を避ける

### 3.2 メッセージ最大数

- 1ブランチにつき最大 **5件程度** の履歴を含める（モデルの最大トークンに応じて調整）
- 長文は要約し、必要ならば `「中略」` という形式に

---

## 🧩 4. 使用モデルごとのテンプレート調整

| モデル名        | プロンプト調整ポイント                      |
|-----------------|-------------------------------------------|
| GPT-4o-mini     | シンプルな指示＋文脈のみで十分             |
| Claude 3 Opus   | 文学的表現を避け、論理的に答える旨を追加  |
| Gemini 1.5 Pro  | アシスタントの指示再確認を明記             |

---

## 📦 5. 最終プロンプト例

```
[SYSTEM]
あなたは論理的で丁寧に回答するアシスタントです。
常に、ユーザーのコンテキストを踏まえて、ブランチの経緯を考慮してください。

[CONTEXT]
- 会話開始: {"content": "LEDディスプレイの仕組みを教えて"}
- ブランチ1: {"content": "それはエネルギー効率的ですか？"}
- 直近の会話: {"content": "その場合の寿命はどのくらいですか？"}

[USER]
LEDの寿命を延ばす具体的な方法は何ですか？
```

---

## 📜 6. 開発上の備考

- LangChain の `ChatPromptTemplate` を使って構築することを想定
- コンテキスト（履歴）生成は LangGraph 側のステート管理に委ねる
- 将来的にメッセージサマリ機能を追加し、長期利用によるトークン肥大を防ぐ

---

以上。