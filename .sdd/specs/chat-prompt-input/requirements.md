# 要件定義書

## 機能概要
チャットAIの会話記憶の取得範囲と結合順序、要約、モデル呼び出し、失敗時の挙動、ログ/安全/使用量管理のルールを定義し、LangGraphによるフロー制御で分岐構造を踏まえた安定した応答生成を実現する。

## ユーザーストーリー
- ユーザーとして、分岐構造を保ったまま適切な履歴と要約に基づいた応答を得たい。なぜなら、話題が枝分かれしても一貫性のあるやり取りを続けたいから。

## 機能要件
### 要件1：会話記憶の取得と結合
- 現在のブランチから親チェーンをルートまで遡り、分岐点より前の共通履歴を必ず含める。
- 兄弟ブランチの履歴は含めない。
- 履歴は時系列で結合する。
- 取得上限は直近40件を基本とし、超過分はメモリ要約（JSON）に置き換える。
- 受入基準：
  - [ ] 現在ブランチの親チェーン履歴のみが取得されること
  - [ ] 分岐点以前の共通履歴が必ず含まれること
  - [ ] 兄弟ブランチの履歴が含まれないこと
  - [ ] 履歴が時系列で結合されること
  - [ ] 40件を超える履歴がメモリ要約（JSON）に置換されること

### 要件2：応答生成フロー
- 処理順序は「履歴取得 → 必要時の要約 → モデル呼び出し → メッセージ保存」とする。
- 優先順位は「履歴 → 要約 → ツール結果」の順とする。
- LangGraphで各処理ノードと遷移を構成する。
- ストリーミング表示を有効にする。
- 受入基準：
  - [ ] 指定の順序で処理が実行されること
  - [ ] 履歴・要約・ツール結果の優先順位が守られること
  - [ ] LangGraphで各処理ノードと遷移が定義されていること
  - [ ] ストリーミング表示が有効になっていること

### 要件3：モデル選択と失敗時の挙動
- モデルはチャット単位で固定する。
- 失敗時は1段のみフォールバックする（固定順）。
- タイムアウト/レート制限時は1回だけ再試行する。
- トークン上限は入力8k、レスポンス長上限は800〜1200の固定値を採用する。
- context超過時は長コンテキスト優先のフォールバック規則を適用する。
- 受入基準：
  - [ ] チャット単位のモデル固定が維持されること
  - [ ] 失敗時のフォールバックが1段のみであること
  - [ ] タイムアウト/レート制限時の再試行が1回だけ行われること
  - [ ] トークン/レスポンス長上限が固定値で適用されること
  - [ ] context超過時のフォールバック規則が適用されること

### 要件4：安全性・ログ・整合性・使用量
- システムプロンプトは固定し、危険入力はFast Gate（ルール）→外部モデレーションの順で判定する。
- 出力も外部モデレーションでチェックする。
- 外部モデレーションはOpenAIの`omni-moderation-latest`を第一選択とする。
- ログはモデル名/トークン量/エラーのみを記録し、PIIは保存しない。
- requestIdによる冪等性を担保し、未指定の場合はサーバで生成する。
- ブランチ整合性の欠損時はエラーで応答する。
- Freeプランの上限チェックと429応答は必須とする。
- タイトル生成は初回応答後に1回だけ行う。
- 受入基準：
  - [ ] Fast Gateで危険入力が拒否されること
  - [ ] 外部モデレーションで危険入力が拒否されること
  - [ ] 出力が外部モデレーションでチェックされること
  - [ ] ログにPIIが保存されないこと
  - [ ] requestIdで冪等性が担保されること
  - [ ] ブランチ整合性欠損時にエラーが返ること
  - [ ] Freeプラン上限時に429が返ること
  - [ ] タイトル生成が初回応答後の1回のみであること

## 非機能要件
- パフォーマンス：中程度の固定トークン/レスポンス上限の範囲で応答が安定すること。
- セキュリティ：危険入力を拒否し、PIIを保存しないこと。
